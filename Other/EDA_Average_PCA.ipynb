{"cells":[{"cell_type":"markdown","metadata":{"id":"0MEqj1FiP711"},"source":["# CIFAR-10 Image Classification "]},{"cell_type":"markdown","metadata":{"id":"dOv42rDMIk1e"},"source":["## References\n","###https://towardsdatascience.com/exploratory-data-analysis-ideas-for-image-classification-d3fc6bbfb2d2"]},{"cell_type":"markdown","source":["# Import Libraries\n","import warnings\n","warnings.filterwarnings('ignore')\n","import os\n","import matplotlib.pyplot as plt\n","import time\n","import calendar\n","from six.moves import cPickle as pickle\n","import numpy as np\n","import cv2\n","from skimage.feature import hog\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import confusion_matrix\n","from sklearn import svm\n","from sklearn.metrics import classification_report,accuracy_score\n","from math import ceil\n","import plotly.express as px"],"metadata":{"id":"yQKxOixRP72O"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Su5Fr7jwP72R"},"outputs":[],"source":["# General Parameters\n","\n","imageSize = 32  \n","channels = 3    \n","classes = 10    \n","trainingDataSize = 50000    \n","testDataSize = 10000        \n","trainingDataFiles = ('./dataset/cifar-10-batches-py/data_batch_1', './dataset/cifar-10-batches-py/data_batch_2', './dataset/cifar-10-batches-py/data_batch_3', './dataset/cifar-10-batches-py/data_batch_4','./dataset/cifar-10-batches-py/data_batch_5') \n","testDataFile = './dataset/cifar-10-batches-py/test_batch' "]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Zoe9Rhl-P72W"},"outputs":[],"source":["def loadData(filename):\n","    '''\n","    Load the data from the given filename\n","\n","    Parameters:\n","    -----------\n","    filename: string\n","        The name of the file containing the data to load\n","\n","    Returns:\n","    --------\n","    theSet['data']:     array of images\n","    theSet['labels']:   array of labels\n","    '''\n","    f = open(filename, 'rb')\n","    theSet = pickle.load(f,encoding='latin1')\n","    f.close()\n","\n","    return theSet['data'], theSet['labels']"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"KrJ64ixxP72Y"},"outputs":[],"source":["def convertImages(origImages):\n","    '''\n","    Convert the images from CIFAR-10 format, to an array of 10000 images each is 32 X 32 X 3 size\n","\n","    Parameters:\n","    -----------\n","    origImages: array\n","        array of images in the CIFAR-10 format\n","\n","    Returns:\n","    --------\n","    images:     array of images each in 32 X 32 X 3 size\n","    '''\n","    images = np.reshape(origImages,(-1, channels, imageSize, imageSize))\n","    images = np.transpose(images, (0,2,3,1))\n","\n","    return images"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Oid7y0f-P72b"},"outputs":[],"source":["def loadTrainingData(filenames):\n","    '''\n","    Load all the training data from all files\n","\n","    Parameters:\n","    -----------\n","    filenames: array of string\n","        An array The name of the file containing the data to load\n","\n","    Returns:\n","    --------\n","    trainingImages: array of the training set images\n","    trainingLabels: array of the training set labels\n","    '''\n","\n","    #Pre-allocate the arrays\n","    trainingImages = np.zeros(shape=[trainingDataSize, imageSize, imageSize, channels], dtype=np.uint8)\n","    trainingLabels = np.zeros(shape=[trainingDataSize], dtype=int)\n","\n","    start=0\n","    for fileName in filenames:\n","\n","      origImages, labels = loadData(fileName)\n","      images = convertImages(origImages)\n","\n","      numOfImages = len(images)\n","      end = start + numOfImages\n","      # print(numOfImages)\n","      trainingImages[start:end, :] = images\n","      trainingLabels[start:end] = labels\n","      start = end\n","\n","    return trainingImages, trainingLabels"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"LCx0kbkqP72Z"},"outputs":[],"source":["def loadTestData(filename):\n","    '''\n","    Load the test data\n","\n","    Parameters:\n","    -----------\n","    filename: string\n","        The name of the file containing the test data\n","\n","    Returns:\n","    --------\n","    testImages: array of images of the test data\n","    testLabels: array of labels of the test data\n","    '''\n","\n","    origTestImages, testLabels = loadData(filename)\n","    testImages = convertImages(origTestImages)\n","\n","    return testImages, testLabels"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"sbVGamycP72d"},"outputs":[],"source":["def currentTime():\n","    '''\n","    Returns the current time in seconds since EPOC\n","    Used to measure how much time each phase took\n","\n","    Returns:\n","    --------\n","    the current time in second since EPOC\n","    '''\n","\n","    return calendar.timegm(time.gmtime())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22015,"status":"ok","timestamp":1669814166854,"user":{"displayName":"AVI TAYAL","userId":"09515673695779566972"},"user_tz":-330},"id":"0mbgPMxm2qjv","outputId":"d7f1a68b-08d8-4133-9de5-108cc8c301f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/Drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/Drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2sR9AJY8dUAB","executionInfo":{"status":"ok","timestamp":1669814166856,"user_tz":-330,"elapsed":42,"user":{"displayName":"AVI TAYAL","userId":"09515673695779566972"}},"outputId":"7b4569c0-f16c-459a-c437-f1f5f4240e36"},"outputs":[{"output_type":"stream","name":"stdout","text":["tar (child): /content/Drive/SharedDrives/CIFAR-10/cifar-10-python.tar.gz: Cannot open: No such file or directory\n","tar (child): Error is not recoverable: exiting now\n","tar: Child returned status 2\n","tar: Error is not recoverable: exiting now\n"]}],"source":["!mkdir -p \"/content/dataset\"\n","!tar -xzf \"/content/Drive/SharedDrives/CIFAR-10/cifar-10-python.tar.gz\" -C \"/content/dataset\""]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1669834267447,"user":{"displayName":"AARYAN CHOKSHI","userId":"17690600184646504935"},"user_tz":-330},"id":"yl2iiGopojmR"},"outputs":[],"source":["# Class values\n","\n","label={}\n","label[0]='airplane' \n","label[1]='automobile' \n","label[2]='bird' \n","label[3]='cat' \n","label[4]='deer' \n","label[5]='dog' \n","label[6]='frog' \n","label[7]='horse' \n","label[8]='ship'\n","label[9]='truck'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"error","timestamp":1669814166857,"user":{"displayName":"AVI TAYAL","userId":"09515673695779566972"},"user_tz":-330},"id":"dW6a7pjgP72h","outputId":"3e1d790a-a378-4dc2-fc0a-25a60f59c76a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading the training set...\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-5bed7bf05499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading the training set...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrentTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainingImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadTrainingData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingDataFiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Took: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtik\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" sec\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-9f910220a05f>\u001b[0m in \u001b[0;36mloadTrainingData\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfileName\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0morigImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvertImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigImages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-15e17646ae8d>\u001b[0m in \u001b[0;36mloadData\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtheSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     '''\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mtheSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/cifar-10-batches-py/data_batch_1'"]}],"source":["print(\"Loading the training set...\"),\n","tik = currentTime()\n","trainingImages, trainingLabels = loadTrainingData(trainingDataFiles)\n","print(\"Took: \" + str(currentTime()-tik) + \" sec\" )"]},{"cell_type":"markdown","metadata":{"id":"Jiqq9aFtogCc"},"source":["## 5 images per image class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QJxg21vHjQcN"},"outputs":[],"source":["list_0 = []\n","list_1 = []\n","list_2 = []\n","list_3 = []\n","list_4 = []\n","list_5 = []\n","list_6 = []\n","list_7 = []\n","list_8 = []\n","list_9 = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VaQqlDF1jQgc"},"outputs":[],"source":["for i in range(trainingImages.shape[0]):\n","\n","  if trainingLabels[i] == 0:\n","    list_0.append(trainingImages[i])\n","\n","  if trainingLabels[i] == 1:\n","    list_1.append(trainingImages[i])\n","    \n","  if trainingLabels[i] == 2:\n","    list_2.append(trainingImages[i])\n","    \n","  if trainingLabels[i] == 3:\n","    list_3.append(trainingImages[i])\n","    \n","  if trainingLabels[i] == 4:\n","    list_4.append(trainingImages[i])\n","    \n","  if trainingLabels[i] == 5:\n","    list_5.append(trainingImages[i])\n","    \n","  if trainingLabels[i] == 6:\n","    list_6.append(trainingImages[i])\n","    \n","  if trainingLabels[i] == 7:\n","    list_7.append(trainingImages[i])\n","    \n","  if trainingLabels[i] == 8:\n","    list_8.append(trainingImages[i])\n","    \n","  if trainingLabels[i] == 9:\n","    list_9.append(trainingImages[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gk_Ma0IxsD7S"},"outputs":[],"source":["num=5\n","\n","list_0 = list_0[:num]\n","list_1 = list_1[:num]\n","list_2 = list_2[:num]\n","list_3 = list_3[:num]\n","list_4 = list_4[:num]\n","list_5 = list_5[:num]\n","list_6 = list_6[:num]\n","list_7 = list_7[:num]\n","list_8 = list_8[:num]\n","list_9 = list_9[:num]"]},{"cell_type":"markdown","metadata":{"id":"6n0GHGye62yF"},"source":["## Average Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0P26-SwJjQoN"},"outputs":[],"source":["def find_mean_img(full_mat, title):\n","  \n","    mean_img = np.mean(full_mat, axis = 0,dtype=int)\n","    mean_img = mean_img.reshape((32,32,3))\n","    \n","    plt.imshow(mean_img,cmap='Greys_r');\n","    plt.title(f'Average {title}')\n","    plt.axis('off')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j6NyERKzjQsW"},"outputs":[],"source":["find_mean_img(list_0,label[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YTA6rl0Hot5c"},"outputs":[],"source":["find_mean_img(list_1,label[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DtW4tNbW70ul"},"outputs":[],"source":["find_mean_img(list_2,label[2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9trqkVpZ73ju"},"outputs":[],"source":["find_mean_img(list_3,label[3])  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GiUl7ql575ra"},"outputs":[],"source":["find_mean_img(list_4,label[4])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hQ49h7e7-hy"},"outputs":[],"source":["find_mean_img(list_5,label[5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArJ0qgvG8BRw"},"outputs":[],"source":["find_mean_img(list_6,label[6])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CfKDjfvY8C85"},"outputs":[],"source":["find_mean_img(list_7,label[7])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JC95iXGr8EyT"},"outputs":[],"source":["find_mean_img(list_8,label[8])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uyM-YGvC8Gr7"},"outputs":[],"source":["find_mean_img(list_9,label[9])"]},{"cell_type":"markdown","metadata":{"id":"TZq1Qu0qoTjJ"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","## HOG Feature descriptors\n","\n","### HOG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9sz93XglpjQS"},"outputs":[],"source":["def hog_vis(img):\n","\n","  cell_size = (8, 8)  # h x w in pixels\n","  block_size = (4, 4)  # h x w in cells\n","  nbins = 9  # number of orientation bins\n","\n","  # winSize is the size of the image cropped to an multiple of the cell size\n","  hog = cv2.HOGDescriptor(_winSize=(img.shape[1] // cell_size[1] * cell_size[1],\n","                                    img.shape[0] // cell_size[0] * cell_size[0]),\n","                          _blockSize=(block_size[1] * cell_size[1],\n","                                      block_size[0] * cell_size[0]),\n","                          _blockStride=(cell_size[1], cell_size[0]),\n","                          _cellSize=(cell_size[1], cell_size[0]),\n","                          _nbins=nbins)\n","\n","  n_cells = (img.shape[0] // cell_size[0], img.shape[1] // cell_size[1])\n","  hog_feats = hog.compute(img)\\\n","                .reshape(n_cells[1] - block_size[1] + 1,\n","                          n_cells[0] - block_size[0] + 1,\n","                          block_size[0], block_size[1], nbins) \\\n","                .transpose((1, 0, 2, 3, 4))  # index blocks by rows first\n","  # hog_feats now contains the gradient amplitudes for each direction,\n","  # for each cell of its group for each group. Indexing is by rows then columns.\n","\n","  gradients = np.zeros((n_cells[0], n_cells[1], nbins))\n","\n","  # count cells (border cells appear less often across overlapping groups)\n","  cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n","\n","  for off_y in range(block_size[0]):\n","      for off_x in range(block_size[1]):\n","          gradients[off_y:n_cells[0] - block_size[0] + off_y + 1,\n","                    off_x:n_cells[1] - block_size[1] + off_x + 1] += hog_feats[:, :, off_y, off_x, :]\n","          cell_count[off_y:n_cells[0] - block_size[0] + off_y + 1,\n","                    off_x:n_cells[1] - block_size[1] + off_x + 1] += 1\n","\n","  # Average gradients\n","  gradients /= cell_count\n","\n","  # Preview\n","  plt.figure()\n","  plt.imshow(img)\n","  plt.show()\n","\n","  bin = 5  # angle is 360 / nbins * direction\n","  plt.pcolor(gradients[:, :, bin], cmap='Greys')\n","  plt.gca().invert_yaxis()\n","  plt.gca().set_aspect('equal', adjustable='box')\n","  plt.colorbar()\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3NrJOa8Eo3xr"},"outputs":[],"source":["hog_vis(list_0[0])\n","print(label[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-391DqNiogDT"},"outputs":[],"source":["hog_vis(list_1[0])\n","print(label[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTsVfrYvodIu"},"outputs":[],"source":["hog_vis(list_2[2])\n","print(label[2])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_QJB8NIvoba9"},"outputs":[],"source":["hog_vis(list_3[2])\n","print(label[3])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0k_2dJ2BjeG7"},"outputs":[],"source":["hog_vis(list_4[2])\n","print(label[4])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LMYHTvgvjeEJ"},"outputs":[],"source":["hog_vis(list_5[1])\n","print(label[5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rweBfvoRjeA0"},"outputs":[],"source":["hog_vis(list_6[0])\n","print(label[6])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DUuOxVrkjd9n"},"outputs":[],"source":["hog_vis(list_7[0])\n","print(label[7])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6xQqzHQyjd55"},"outputs":[],"source":["hog_vis(list_8[2])\n","print(label[8])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dY3T0O17jd2B"},"outputs":[],"source":["hog_vis(list_9[0])\n","print(label[9])"]},{"cell_type":"markdown","metadata":{"id":"E2agH3X48m1V"},"source":["## Eigen images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKb385aO3N5h"},"outputs":[],"source":["def plot_pca(imageSet):\n","  \n","  pca = PCA()\n","  components = pca.fit_transform(imageSet)\n","  labels = {\n","      str(i): f\"PC {i+1} ({var:.1f}%)\"\n","      for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n","  }\n","\n","  classLabels=[]\n","  for i in range(10):\n","    classLabels.append(label[i])\n","\n","  fig = px.scatter_3d(imageSet, x=1, y=2, z=3, color=classLabels)\n","  fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUbXx55xTEnt"},"outputs":[],"source":["def plot_pca_matrix(imageSet):\n","  \n","  pca = PCA()\n","  components = pca.fit_transform(imageSet)\n","  labels = {\n","      str(i): f\"PC {i+1} ({var:.1f}%)\"\n","      for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n","  }\n","\n","  classLabels=[]\n","  for i in range(10):\n","    classLabels.append(label[i])\n","\n","  fig = px.scatter_matrix(\n","      components,\n","      labels=labels,\n","      dimensions=range(4),\n","      color=classLabels\n","  )\n","  fig.update_traces(diagonal_visible=False)\n","  fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CGNWJaq0Hklq"},"outputs":[],"source":["imageSet = np.zeros((10,32*32*3),dtype=int)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bzV5NKzwIu7E"},"outputs":[],"source":["imageSet[0] = list_0[0].flatten()\n","imageSet[1] = list_1[0].flatten()\n","imageSet[2] = list_2[2].flatten()\n","imageSet[3] = list_3[2].flatten()\n","imageSet[4] = list_4[2].flatten()\n","imageSet[5] = list_5[2].flatten()\n","imageSet[6] = list_6[0].flatten()\n","imageSet[7] = list_7[2].flatten()\n","imageSet[8] = list_8[2].flatten()\n","imageSet[9] = list_9[0].flatten()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RdWBeDyIwha"},"outputs":[],"source":["plot_pca(imageSet)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMllO6SUTOSl"},"outputs":[],"source":["plot_pca_matrix(imageSet)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1cmSBIVVkFtUGV652eHijXC534w0laq3j","timestamp":1669711335290},{"file_id":"1nX3JmQKK1oWNBIVHTy27l-_R7yI6ZXvp","timestamp":1669449655569},{"file_id":"1UngqbMRvZHWTpkDV3IUxPO1oaT7lOH0C","timestamp":1669393184856}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}